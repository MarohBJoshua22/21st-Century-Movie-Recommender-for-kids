# -*- coding: utf-8 -*-
"""2311336SWE6204.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MZAUnlqfDM4L4sojpchL1UEcHREl-xNs
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Loading dataset
path = "/content/drive/MyDrive/vld_mvi_dst.csv"
df = pd.read_csv(path)

df.head(10)

# DATA PRE-PROCESSING

# Filter movies released in the 21st century with 'Children' and 'Animation' genres

df['year'] = df['title'].str.extract(r'\((\d{4})\)').astype(float)
# This Extracts the year of release from the 'title' column and adds it as a new column 'year'.

df = df[(df['year'] >= 2000) & (df['genres'].str.contains('Children')) & (df['genres'].str.contains('Animation'))]
# This Filters the dataset to include movies released in the 21st century with 'Children' and 'Animation' genres.

df.head()

# TF-IDF Vectorization for genres
vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split('|')) #Initializes a TF-IDF vectorizer to convert the 'genres' column into numerical features
X = vectorizer.fit_transform(df['genres']) #Transforming the 'genres' data into a TF-IDF matrix and assigning to new variable X

df.head(10)

# Determining the best/optimal number of clusters using the Silhouette score and inertia
silhouette_scores = []
inertia_values = []
cluster_range = range(2, 15)  # The Range of clusters Attempted

for n_clusters in cluster_range:
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(X)
    cluster_labels = kmeans.labels_
    silhouette_avg = silhouette_score(X, cluster_labels)
    silhouette_scores.append(silhouette_avg)
    inertia_values.append(kmeans.inertia_)

df['cluster'] = kmeans.fit_predict(X) #Assigning cluster labels to the dataframe based on the clustering results with the optimal number of clusters. For visualization purposes

# Plotting Silhouette scores
plt.plot(cluster_range, silhouette_scores, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score for Different Number of Clusters')
plt.show()

# Plotting Inertia values
plt.plot(cluster_range, inertia_values, c="blue", marker='*')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Inertia for Different Number of Clusters')
plt.show()

# Densifying the TF-IDF matrix
X_dense = X.todense()

# Converting X_dense to numpy array
X_dense_array = np.asarray(X_dense)

# Plotting the clusters
plt.figure(figsize=(8, 6))
plt.scatter(X_dense_array[:, 0], X_dense_array[:, 1], c=kmeans.labels_, cmap='viridis', alpha=0.5)
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='*', label='Centroids')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('K-means Clustering')
plt.legend()
plt.show()

# Performing PCA on the TF-IDF matrix X
# This code reduces the dimensionality of to 2 componenets
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X.toarray())

# Data Visualization: Plot Clusters

# Plot the clusters using centroids
plt.figure(figsize=(8, 6))
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=100, c='red', marker='*', label='Centroids')

# Plot the data points
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans.labels_, cmap='viridis', alpha=0.5)
plt.xlabel('X')
plt.ylabel('Y')
plt.title('K-means Clusters')
plt.legend()
plt.show()

# PCA Transformation
pca = PCA(n_components=3)  # 3 principal components for 3D plot
X_pca = pca.fit_transform(X.toarray())

# Plotting Data Points in 3D PCA Axis
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plotting clusters
for cluster in df['cluster'].unique():
    ax.scatter(X_pca[df['cluster'] == cluster][:, 0],
               X_pca[df['cluster'] == cluster][:, 1],
               X_pca[df['cluster'] == cluster][:, 2],
               label=f'Cluster {cluster}', alpha=0.7)

ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
ax.set_title('3D PCA Plot of Movie Clusters')
ax.legend()

plt.show()

def recommend_movie_with_reason(title):
  # Geting the cluster of the input movie
  movie_cluster = df[df['title'] == title]['cluster'].values[0]

  # Finding similar movies in the same cluster except the input movie
  similar_movies = df[(df['cluster'] == movie_cluster) & (df['title'] != title)]

  # Sorting by rating in descending order
  sorted_movies = similar_movies.sort_values(by='rating', ascending=False)

  # Removing duplicates and get the top 5 unique movies
  unique_movies = sorted_movies.drop_duplicates(subset='title').head(5)

  # Generating dynamic reasons for recommending each movie
  reasons = []
  action_words = ['Gives you', 'Takes you on', 'Provides', 'Delivers']
  theme_words = ['stories', 'narratives', 'plots', 'adventures']

  for idx, movie in unique_movies.iterrows():
      # Extracting genres and create a storyline based on them
      genres = movie['genres'].split('|')
      storyline = ''
      if 'Action' in genres:
          storyline += 'action-packed adventure '
      if 'Drama' in genres:
          storyline += 'dramatic and emotional journey '
      if 'Comedy' in genres:
          storyline += 'hilarious and light-hearted moments '
      if 'Fantasy' in genres:
          storyline += 'magical and imaginative world '

      # Constructing the reason paragraph
      action_word = action_words[idx % len(action_words)]  # this Selects a dynamic action word
      theme_word = theme_words[idx % len(theme_words)]  # this Selects a dynamic theme word
      reason = f"{action_word} a {storyline.lower().strip()} that resonates with the {theme_word} of {title}."
      reasons.append(reason)

  return unique_movies['title'].tolist(), reasons

# Testing the recommend function
movie_title = 'Rio 2 (2014)'
recommended_movies, reasons = recommend_movie_with_reason(movie_title)
print(f"Movies similar to '{movie_title}':")
for movie, reason in zip(recommended_movies, reasons):
    print(f"{movie}: \n{reason}\n")
